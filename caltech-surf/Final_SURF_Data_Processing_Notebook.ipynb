{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMVyWiox0OVKCtzokh+E2Iv",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/semenko/liquid-cell-atlas/blob/main/Final_SURF_Data_Processing_Notebook.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import Necessary Packages"
      ],
      "metadata": {
        "id": "cInHkTpG1ff5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will be needing some bio-related dataset packages such as pyBigWig, pybedtools, and deeptools."
      ],
      "metadata": {
        "id": "43vvBuTz6xnV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pyBigWig pybedtools gunzip bedparse deeptools pyGenomeTracks\n",
        "!apt install bedtools"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Vzci4Vzz3iTg",
        "outputId": "060f50d1-ff99-4eaf-a54f-4d74ab5762aa"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pyBigWig\n",
            "  Downloading pyBigWig-0.3.18.tar.gz (64 kB)\n",
            "\u001b[K     |████████████████████████████████| 64 kB 2.1 MB/s \n",
            "\u001b[?25hCollecting pybedtools\n",
            "  Downloading pybedtools-0.9.0.tar.gz (12.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 12.5 MB 9.2 MB/s \n",
            "\u001b[?25hCollecting gunzip\n",
            "  Downloading gunzip-0.1.10-py2.py3-none-any.whl (3.0 kB)\n",
            "Collecting bedparse\n",
            "  Downloading bedparse-0.2.3-py3-none-any.whl (21 kB)\n",
            "Collecting deeptools\n",
            "  Downloading deepTools-3.5.1-py3-none-any.whl (233 kB)\n",
            "\u001b[K     |████████████████████████████████| 233 kB 49.8 MB/s \n",
            "\u001b[?25hCollecting pyGenomeTracks\n",
            "  Downloading pyGenomeTracks-3.7-py2.py3-none-any.whl (112 kB)\n",
            "\u001b[K     |████████████████████████████████| 112 kB 47.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from pybedtools) (1.15.0)\n",
            "Collecting pysam\n",
            "  Downloading pysam-0.20.0-cp37-cp37m-manylinux_2_24_x86_64.whl (15.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 15.4 MB 32.0 MB/s \n",
            "\u001b[?25hCollecting microapp>=0.2.3\n",
            "  Downloading microapp-0.3.15-py2.py3-none-any.whl (31 kB)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from bedparse) (57.4.0)\n",
            "Collecting argparse\n",
            "  Downloading argparse-1.4.0-py2.py3-none-any.whl (23 kB)\n",
            "Collecting numpydoc>=0.5\n",
            "  Downloading numpydoc-1.5.0-py3-none-any.whl (52 kB)\n",
            "\u001b[K     |████████████████████████████████| 52 kB 981 kB/s \n",
            "\u001b[?25hRequirement already satisfied: plotly>=4.9 in /usr/local/lib/python3.7/dist-packages (from deeptools) (5.5.0)\n",
            "Requirement already satisfied: numpy>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from deeptools) (1.21.6)\n",
            "Collecting deeptoolsintervals>=0.1.8\n",
            "  Downloading deeptoolsintervals-0.1.9.tar.gz (41 kB)\n",
            "\u001b[K     |████████████████████████████████| 41 kB 136 kB/s \n",
            "\u001b[?25hCollecting py2bit>=0.2.0\n",
            "  Downloading py2bit-0.3.0.tar.gz (16 kB)\n",
            "Collecting matplotlib>=3.3.0\n",
            "  Downloading matplotlib-3.5.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.whl (11.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 11.2 MB 36.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.7/dist-packages (from deeptools) (1.7.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.3.0->deeptools) (2.8.2)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.3.0->deeptools) (1.4.4)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.3.0->deeptools) (0.11.0)\n",
            "Requirement already satisfied: pyparsing>=2.2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.3.0->deeptools) (3.0.9)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.3.0->deeptools) (7.1.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.3.0->deeptools) (21.3)\n",
            "Collecting fonttools>=4.22.0\n",
            "  Downloading fonttools-4.38.0-py3-none-any.whl (965 kB)\n",
            "\u001b[K     |████████████████████████████████| 965 kB 46.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from kiwisolver>=1.0.1->matplotlib>=3.3.0->deeptools) (4.1.1)\n",
            "Collecting sphinx>=4.2\n",
            "  Downloading sphinx-5.3.0-py3-none-any.whl (3.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.2 MB 30.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: Jinja2>=2.10 in /usr/local/lib/python3.7/dist-packages (from numpydoc>=0.5->deeptools) (2.11.3)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from Jinja2>=2.10->numpydoc>=0.5->deeptools) (2.0.1)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.7/dist-packages (from plotly>=4.9->deeptools) (8.1.0)\n",
            "Collecting sphinxcontrib-devhelp\n",
            "  Downloading sphinxcontrib_devhelp-1.0.2-py2.py3-none-any.whl (84 kB)\n",
            "\u001b[K     |████████████████████████████████| 84 kB 3.3 MB/s \n",
            "\u001b[?25hCollecting Pygments>=2.12\n",
            "  Downloading Pygments-2.13.0-py3-none-any.whl (1.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1 MB 45.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: imagesize>=1.3 in /usr/local/lib/python3.7/dist-packages (from sphinx>=4.2->numpydoc>=0.5->deeptools) (1.4.1)\n",
            "Requirement already satisfied: sphinxcontrib-serializinghtml>=1.1.5 in /usr/local/lib/python3.7/dist-packages (from sphinx>=4.2->numpydoc>=0.5->deeptools) (1.1.5)\n",
            "Requirement already satisfied: importlib-metadata>=4.8 in /usr/local/lib/python3.7/dist-packages (from sphinx>=4.2->numpydoc>=0.5->deeptools) (4.13.0)\n",
            "Collecting sphinxcontrib-qthelp\n",
            "  Downloading sphinxcontrib_qthelp-1.0.3-py2.py3-none-any.whl (90 kB)\n",
            "\u001b[K     |████████████████████████████████| 90 kB 8.3 MB/s \n",
            "\u001b[?25hCollecting Jinja2>=2.10\n",
            "  Downloading Jinja2-3.1.2-py3-none-any.whl (133 kB)\n",
            "\u001b[K     |████████████████████████████████| 133 kB 39.3 MB/s \n",
            "\u001b[?25hCollecting sphinxcontrib-htmlhelp>=2.0.0\n",
            "  Downloading sphinxcontrib_htmlhelp-2.0.0-py2.py3-none-any.whl (100 kB)\n",
            "\u001b[K     |████████████████████████████████| 100 kB 9.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: docutils<0.20,>=0.14 in /usr/local/lib/python3.7/dist-packages (from sphinx>=4.2->numpydoc>=0.5->deeptools) (0.17.1)\n",
            "Requirement already satisfied: alabaster<0.8,>=0.7 in /usr/local/lib/python3.7/dist-packages (from sphinx>=4.2->numpydoc>=0.5->deeptools) (0.7.12)\n",
            "Collecting sphinxcontrib-applehelp\n",
            "  Downloading sphinxcontrib_applehelp-1.0.2-py2.py3-none-any.whl (121 kB)\n",
            "\u001b[K     |████████████████████████████████| 121 kB 60.2 MB/s \n",
            "\u001b[?25hCollecting sphinxcontrib-jsmath\n",
            "  Downloading sphinxcontrib_jsmath-1.0.1-py2.py3-none-any.whl (5.1 kB)\n",
            "Requirement already satisfied: requests>=2.5.0 in /usr/local/lib/python3.7/dist-packages (from sphinx>=4.2->numpydoc>=0.5->deeptools) (2.23.0)\n",
            "Requirement already satisfied: babel>=2.9 in /usr/local/lib/python3.7/dist-packages (from sphinx>=4.2->numpydoc>=0.5->deeptools) (2.10.3)\n",
            "Requirement already satisfied: snowballstemmer>=2.0 in /usr/local/lib/python3.7/dist-packages (from sphinx>=4.2->numpydoc>=0.5->deeptools) (2.2.0)\n",
            "Requirement already satisfied: pytz>=2015.7 in /usr/local/lib/python3.7/dist-packages (from babel>=2.9->sphinx>=4.2->numpydoc>=0.5->deeptools) (2022.5)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.8->sphinx>=4.2->numpydoc>=0.5->deeptools) (3.10.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.5.0->sphinx>=4.2->numpydoc>=0.5->deeptools) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.5.0->sphinx>=4.2->numpydoc>=0.5->deeptools) (2022.9.24)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.5.0->sphinx>=4.2->numpydoc>=0.5->deeptools) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.5.0->sphinx>=4.2->numpydoc>=0.5->deeptools) (1.24.3)\n",
            "Collecting bx-python>=0.8.13\n",
            "  Downloading bx_python-0.9.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.3 MB 37.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pytest in /usr/local/lib/python3.7/dist-packages (from pyGenomeTracks) (3.6.4)\n",
            "Collecting hicmatrix>=15\n",
            "  Downloading HiCMatrix-15-py3-none-any.whl (37 kB)\n",
            "Collecting pyfaidx>=0.1.3\n",
            "  Downloading pyfaidx-0.7.1.tar.gz (103 kB)\n",
            "\u001b[K     |████████████████████████████████| 103 kB 53.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: intervaltree>=2.1.0 in /usr/local/lib/python3.7/dist-packages (from pyGenomeTracks) (2.1.0)\n",
            "Collecting matplotlib>=3.3.0\n",
            "  Downloading matplotlib-3.5.1-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.whl (11.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 11.2 MB 44.5 MB/s \n",
            "\u001b[?25hCollecting future>=0.17.0\n",
            "  Downloading future-0.18.2.tar.gz (829 kB)\n",
            "\u001b[K     |████████████████████████████████| 829 kB 48.2 MB/s \n",
            "\u001b[?25hCollecting gffutils>=0.9\n",
            "  Downloading gffutils-0.11.1.tar.gz (1.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.6 MB 43.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.20 in /usr/local/lib/python3.7/dist-packages (from pyGenomeTracks) (4.64.1)\n",
            "Collecting argh>=0.26.2\n",
            "  Downloading argh-0.26.2-py2.py3-none-any.whl (30 kB)\n",
            "Collecting argcomplete>=1.9.4\n",
            "  Downloading argcomplete-2.0.0-py2.py3-none-any.whl (37 kB)\n",
            "Collecting simplejson\n",
            "  Downloading simplejson-3.17.6-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (130 kB)\n",
            "\u001b[K     |████████████████████████████████| 130 kB 52.8 MB/s \n",
            "\u001b[?25hCollecting intervaltree>=2.1.0\n",
            "  Downloading intervaltree-3.1.0.tar.gz (32 kB)\n",
            "Collecting cooler>=0.8.9\n",
            "  Downloading cooler-0.8.11-py2.py3-none-any.whl (100 kB)\n",
            "\u001b[K     |████████████████████████████████| 100 kB 8.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pandas>=0.25.* in /usr/local/lib/python3.7/dist-packages (from hicmatrix>=15->pyGenomeTracks) (1.3.5)\n",
            "Requirement already satisfied: tables>=3.5.* in /usr/local/lib/python3.7/dist-packages (from hicmatrix>=15->pyGenomeTracks) (3.7.0)\n",
            "Collecting multiprocess\n",
            "  Downloading multiprocess-0.70.14-py37-none-any.whl (115 kB)\n",
            "\u001b[K     |████████████████████████████████| 115 kB 51.5 MB/s \n",
            "\u001b[?25hCollecting cytoolz<0.11\n",
            "  Downloading cytoolz-0.10.1.tar.gz (475 kB)\n",
            "\u001b[K     |████████████████████████████████| 475 kB 41.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: h5py>=2.5 in /usr/local/lib/python3.7/dist-packages (from cooler>=0.8.9->hicmatrix>=15->pyGenomeTracks) (3.1.0)\n",
            "Collecting asciitree\n",
            "  Downloading asciitree-0.3.3.tar.gz (4.0 kB)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from cooler>=0.8.9->hicmatrix>=15->pyGenomeTracks) (6.0)\n",
            "Requirement already satisfied: click>=7 in /usr/local/lib/python3.7/dist-packages (from cooler>=0.8.9->hicmatrix>=15->pyGenomeTracks) (7.1.2)\n",
            "Collecting pypairix\n",
            "  Downloading pypairix-0.3.7.tar.gz (65 kB)\n",
            "\u001b[K     |████████████████████████████████| 65 kB 4.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: toolz>=0.8.0 in /usr/local/lib/python3.7/dist-packages (from cytoolz<0.11->cooler>=0.8.9->hicmatrix>=15->pyGenomeTracks) (0.12.0)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py>=2.5->cooler>=0.8.9->hicmatrix>=15->pyGenomeTracks) (1.5.2)\n",
            "Requirement already satisfied: sortedcontainers<3.0,>=2.0 in /usr/local/lib/python3.7/dist-packages (from intervaltree>=2.1.0->pyGenomeTracks) (2.4.0)\n",
            "Requirement already satisfied: numexpr>=2.6.2 in /usr/local/lib/python3.7/dist-packages (from tables>=3.5.*->hicmatrix>=15->pyGenomeTracks) (2.8.4)\n",
            "Requirement already satisfied: dill>=0.3.6 in /usr/local/lib/python3.7/dist-packages (from multiprocess->cooler>=0.8.9->hicmatrix>=15->pyGenomeTracks) (0.3.6)\n",
            "Requirement already satisfied: more-itertools>=4.0.0 in /usr/local/lib/python3.7/dist-packages (from pytest->pyGenomeTracks) (9.0.0)\n",
            "Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.7/dist-packages (from pytest->pyGenomeTracks) (22.1.0)\n",
            "Requirement already satisfied: pluggy<0.8,>=0.5 in /usr/local/lib/python3.7/dist-packages (from pytest->pyGenomeTracks) (0.7.1)\n",
            "Requirement already satisfied: py>=1.5.0 in /usr/local/lib/python3.7/dist-packages (from pytest->pyGenomeTracks) (1.11.0)\n",
            "Requirement already satisfied: atomicwrites>=1.0 in /usr/local/lib/python3.7/dist-packages (from pytest->pyGenomeTracks) (1.4.1)\n",
            "Building wheels for collected packages: pyBigWig, pybedtools, deeptoolsintervals, py2bit, future, gffutils, cytoolz, intervaltree, pyfaidx, asciitree, pypairix\n",
            "  Building wheel for pyBigWig (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyBigWig: filename=pyBigWig-0.3.18-cp37-cp37m-linux_x86_64.whl size=197055 sha256=a8308d34b74626236eec730c83b0168a8a6573a650b5c61c59b3f3e07c0b6a3b\n",
            "  Stored in directory: /root/.cache/pip/wheels/28/eb/46/c761563ba38bd516bcc6accde3d4188cd84eec067f9201cbec\n",
            "  Building wheel for pybedtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pybedtools: filename=pybedtools-0.9.0-cp37-cp37m-linux_x86_64.whl size=13616804 sha256=1117bd34e26a95fd479d786378c5dd2f77fb71bb2ab28a5df83be07cdd1a54cb\n",
            "  Stored in directory: /root/.cache/pip/wheels/7a/44/0d/3a7449885adaf8ebb157da8c3c834a712f48b3b3b84ba51dda\n",
            "  Building wheel for deeptoolsintervals (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for deeptoolsintervals: filename=deeptoolsintervals-0.1.9-cp37-cp37m-linux_x86_64.whl size=109455 sha256=e7cfb56fb0aa7c393396a0822f08593d8b88bc238e17d680df68d6c1fa5b2b3b\n",
            "  Stored in directory: /root/.cache/pip/wheels/b5/62/44/d9b409078c4ff6f98b59f31816291b08ffe1e55091fdaf5d12\n",
            "  Building wheel for py2bit (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for py2bit: filename=py2bit-0.3.0-cp37-cp37m-linux_x86_64.whl size=44551 sha256=637ca28c9769f267638789839a1299a688a89e2be5fd282faa7b37dbeeba208a\n",
            "  Stored in directory: /root/.cache/pip/wheels/a3/6f/d1/85fafa2537b2f5744215f97523911abde76d6e3f471095c0e0\n",
            "  Building wheel for future (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for future: filename=future-0.18.2-py3-none-any.whl size=491070 sha256=13d6b099772c5baff95aeb685c905ab2b01f1c7e3370e7fb3b89307dc339c113\n",
            "  Stored in directory: /root/.cache/pip/wheels/56/b0/fe/4410d17b32f1f0c3cf54cdfb2bc04d7b4b8f4ae377e2229ba0\n",
            "  Building wheel for gffutils (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gffutils: filename=gffutils-0.11.1-py3-none-any.whl size=1619367 sha256=c4aa7647910b9e7449f4ee44c4c278cda52ec0e947385e0940d5caf620eac765\n",
            "  Stored in directory: /root/.cache/pip/wheels/66/ab/9e/457aaf2bb72c3d8afe5f1aa9b1cc40b16d76762ddc0da7bdf5\n",
            "  Building wheel for cytoolz (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for cytoolz: filename=cytoolz-0.10.1-cp37-cp37m-linux_x86_64.whl size=1238201 sha256=96facd13ba23b2e67c5530f58b190f6cd0d7b1cfd299f39be5604188fca877cd\n",
            "  Stored in directory: /root/.cache/pip/wheels/db/f0/a6/8d56aaec49585b245b0694bf8972e50a3b2a83331657ea7e95\n",
            "  Building wheel for intervaltree (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for intervaltree: filename=intervaltree-3.1.0-py2.py3-none-any.whl size=26119 sha256=52d8947062c64ee54444bde6c0e42afd9f4928386a4eb0ee8d15cfb0b30e6a2b\n",
            "  Stored in directory: /root/.cache/pip/wheels/16/85/bd/1001cbb46dcfb71c2001cd7401c6fb250392f22a81ce3722f7\n",
            "  Building wheel for pyfaidx (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyfaidx: filename=pyfaidx-0.7.1-py3-none-any.whl size=27747 sha256=8109b33c68e7a85c37b18ba2105a75c03dfb9787d10b343f3e640c97672701a6\n",
            "  Stored in directory: /root/.cache/pip/wheels/1a/d6/99/7334c4d11bfb574e6d6ea706256053b268a12f2127af1cfd40\n",
            "  Building wheel for asciitree (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for asciitree: filename=asciitree-0.3.3-py3-none-any.whl size=5050 sha256=9d0a3de371f43141e0ff96b1e397a99906b041ae5bf970fd7d581b5b12c61a6b\n",
            "  Stored in directory: /root/.cache/pip/wheels/12/1c/38/0def51e15add93bff3f4bf9c248b94db0839b980b8535e72a0\n",
            "  Building wheel for pypairix (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pypairix: filename=pypairix-0.3.7-cp37-cp37m-linux_x86_64.whl size=142861 sha256=52279c9b697ce325816a8472f82918fb277cd5c9281e246faa2d87953e6732c4\n",
            "  Stored in directory: /root/.cache/pip/wheels/c7/8e/06/7c0d1ddd07b0311ea0b859c34e63b395cb931857033ab3cff3\n",
            "Successfully built pyBigWig pybedtools deeptoolsintervals py2bit future gffutils cytoolz intervaltree pyfaidx asciitree pypairix\n",
            "Installing collected packages: sphinxcontrib-qthelp, sphinxcontrib-jsmath, sphinxcontrib-htmlhelp, sphinxcontrib-devhelp, sphinxcontrib-applehelp, simplejson, pypairix, Pygments, pyfaidx, multiprocess, Jinja2, cytoolz, asciitree, sphinx, pysam, intervaltree, fonttools, cooler, argh, argcomplete, pyBigWig, pybedtools, py2bit, numpydoc, microapp, matplotlib, hicmatrix, gffutils, future, deeptoolsintervals, bx-python, argparse, pyGenomeTracks, gunzip, deeptools, bedparse\n",
            "  Attempting uninstall: Pygments\n",
            "    Found existing installation: Pygments 2.6.1\n",
            "    Uninstalling Pygments-2.6.1:\n",
            "      Successfully uninstalled Pygments-2.6.1\n",
            "  Attempting uninstall: Jinja2\n",
            "    Found existing installation: Jinja2 2.11.3\n",
            "    Uninstalling Jinja2-2.11.3:\n",
            "      Successfully uninstalled Jinja2-2.11.3\n",
            "  Attempting uninstall: sphinx\n",
            "    Found existing installation: Sphinx 1.8.6\n",
            "    Uninstalling Sphinx-1.8.6:\n",
            "      Successfully uninstalled Sphinx-1.8.6\n",
            "  Attempting uninstall: intervaltree\n",
            "    Found existing installation: intervaltree 2.1.0\n",
            "    Uninstalling intervaltree-2.1.0:\n",
            "      Successfully uninstalled intervaltree-2.1.0\n",
            "  Attempting uninstall: matplotlib\n",
            "    Found existing installation: matplotlib 3.2.2\n",
            "    Uninstalling matplotlib-3.2.2:\n",
            "      Successfully uninstalled matplotlib-3.2.2\n",
            "  Attempting uninstall: future\n",
            "    Found existing installation: future 0.16.0\n",
            "    Uninstalling future-0.16.0:\n",
            "      Successfully uninstalled future-0.16.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "ipython 7.9.0 requires jedi>=0.10, which is not installed.\n",
            "flask 1.1.4 requires Jinja2<3.0,>=2.10.1, but you have jinja2 3.1.2 which is incompatible.\u001b[0m\n",
            "Successfully installed Jinja2-3.1.2 Pygments-2.13.0 argcomplete-2.0.0 argh-0.26.2 argparse-1.4.0 asciitree-0.3.3 bedparse-0.2.3 bx-python-0.9.0 cooler-0.8.11 cytoolz-0.10.1 deeptools-3.5.1 deeptoolsintervals-0.1.9 fonttools-4.38.0 future-0.18.2 gffutils-0.11.1 gunzip-0.1.10 hicmatrix-15 intervaltree-3.1.0 matplotlib-3.5.1 microapp-0.3.15 multiprocess-0.70.14 numpydoc-1.5.0 py2bit-0.3.0 pyBigWig-0.3.18 pyGenomeTracks-3.7 pybedtools-0.9.0 pyfaidx-0.7.1 pypairix-0.3.7 pysam-0.20.0 simplejson-3.17.6 sphinx-5.3.0 sphinxcontrib-applehelp-1.0.2 sphinxcontrib-devhelp-1.0.2 sphinxcontrib-htmlhelp-2.0.0 sphinxcontrib-jsmath-1.0.1 sphinxcontrib-qthelp-1.0.3\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "argparse",
                  "matplotlib",
                  "mpl_toolkits",
                  "pygments",
                  "sphinxcontrib"
                ]
              }
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "The following package was automatically installed and is no longer required:\n",
            "  libnvidia-common-460\n",
            "Use 'apt autoremove' to remove it.\n",
            "The following NEW packages will be installed:\n",
            "  bedtools\n",
            "0 upgraded, 1 newly installed, 0 to remove and 4 not upgraded.\n",
            "Need to get 577 kB of archives.\n",
            "After this operation, 2,040 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu bionic/universe amd64 bedtools amd64 2.26.0+dfsg-5 [577 kB]\n",
            "Fetched 577 kB in 0s (1,401 kB/s)\n",
            "Selecting previously unselected package bedtools.\n",
            "(Reading database ... 123942 files and directories currently installed.)\n",
            "Preparing to unpack .../bedtools_2.26.0+dfsg-5_amd64.deb ...\n",
            "Unpacking bedtools (2.26.0+dfsg-5) ...\n",
            "Setting up bedtools (2.26.0+dfsg-5) ...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "gR9ANdIH1Tqp"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import io\n",
        "import itertools\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "import csv\n",
        "import os as os\n",
        "import urllib\n",
        "import pickle\n",
        "import json\n",
        "import pyBigWig\n",
        "import pybedtools\n",
        "import sys\n",
        "import re"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Processing"
      ],
      "metadata": {
        "id": "XW2IOexV2cGb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## TSV of Links to Data"
      ],
      "metadata": {
        "id": "gRMGKpYz2fJM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The TSV contains the links to all of the datasets on the site, as well as their corresponding cell types, file types, and more.\n",
        "\n",
        "We filter the file to get rid of individuals with diseases, and only keep the datasets with the bigWig file format. We also only keep bisulfite sequencing data."
      ],
      "metadata": {
        "id": "8n-Imv0D2jMG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Get blueprint dataset\n",
        "! wget 'http://dcc.blueprint-epigenome.eu/data/blueprint_files.tsv' -N\n",
        "data_tsv = pd.read_csv('blueprint_files.tsv', sep='\\t')\n",
        "\n",
        "# Only keep bisulfite sequencing data from non-diseased individuals, formatted as a bigWig file.\n",
        "noDisease_bw_data = data_tsv[(data_tsv['Disease'] == 'None') & \n",
        "                             (data_tsv['Format'] == 'bigWig') & \n",
        "                             (data_tsv['Experiment'] == 'Bisulfite-Seq')]"
      ],
      "metadata": {
        "id": "rsNjnrAw2dAe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Gene Locations"
      ],
      "metadata": {
        "id": "25FzXOvM3CJy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Download the human genomic database and convert it into a bed file."
      ],
      "metadata": {
        "id": "LB0SFzIM3MP8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Get dataset of human genes\n",
        "! wget https://ftp.ebi.ac.uk/pub/databases/gencode/Gencode_human/release_40/gencode.v40.annotation.gtf.gz\n",
        "! gunzip gencode.v40.annotation.gtf.gz\n",
        "\n",
        "# Do gtf to bed conversion\n",
        "! bedparse gtf2bed <gencode.v40.annotation.gtf> output.bed --extraFields gene_id,gene_name\n",
        "output_bed = pybedtools.BedTool(\"output.bed\")\n",
        "\n",
        "os.remove(\"gencode.v40.annotation.gtf\")"
      ],
      "metadata": {
        "id": "HbBFgWIH269d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Convert the bed file into a pandas dataframe, and remove any unneccessary colummns! The only ones we keep are those relating to the chromosome number, the start and end base pair, the strandedness, the gene_id, and gene_name."
      ],
      "metadata": {
        "id": "umImfv-E3pdi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert be file to pandas dataframe and delete unnecessary columns\n",
        "gene_loc = pd.read_csv(\"coding_exon.bed\", sep = '\\t', names = [\"chrom\", \"start\", \"end\", \"name\", \"e1\", \"strand\"], index_col = False)\n",
        "gene_loc = gene_loc[[\"chrom\", \"start\", \"end\", \"strand\", \"name\"]]\n",
        "gene_loc = gene_loc.drop(gene_loc[gene_loc[\"chrom\"] == \"chrM\"].index) # Don't need chromosome M data\n",
        "gene_loc.reset_index(drop=True, inplace=True)\n",
        "\n",
        "gene_locs = {}\n",
        "\n",
        "# List of all unique gene names in the dataset\n",
        "gene_names = list(set(gene_loc[\"name\"]))\n",
        "gene_names = list(set([x[:15] for x in gene_names]))\n",
        "\n",
        "# Map each gene name to its (chromosome, starting base pair, ending base pair)\n",
        "for i in tqdm(range(len(gene_names))):\n",
        "    name = gene_names[i]\n",
        "    gene = gene_loc[gene_loc[\"name\"].str.contains(name)]\n",
        "    try:\n",
        "        chr = re.search('chr([0-9]{1,2}|X|Y)', str(gene[\"chrom\"])).group(0)\n",
        "        start_loc = gene.iloc[0][\"start\"]\n",
        "        end_loc = gene.iloc[0][\"end\"]\n",
        "\n",
        "        gene_locs[name] = (chr, start_loc, end_loc)\n",
        "    except:\n",
        "        continue"
      ],
      "metadata": {
        "id": "lZCcnuji3s-q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for name in gene_names:\n",
        "    if name not in gene_locs.keys():\n",
        "        gene_names.remove(name)"
      ],
      "metadata": {
        "id": "3hhAjj_K33jj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Making the Dataset"
      ],
      "metadata": {
        "id": "dOy7iMFq3-kf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "For each cell example in the Blueprint methylation database, we want the average methylation over all genes. The final dataset will be a table, with cell type as the rows, and gene names as the columns.\n",
        "\n",
        "To do this, we iterate over each example in the Blueprint methylation database. Each example contains a cell type, as well as its average methylation at millions of base pairs. First, the cell type is set as the label. We then iterate over all gene locations, and average over all methylation records from the starting to the ending points of each gene. \n",
        "\n",
        "Thus, each cell type label has hundreds of thousands of average methylation measurements, one for each gene in the human body."
      ],
      "metadata": {
        "id": "6ZWScBHz4vS0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "CHROMOSOMES = [\"chr\" + str(i) for i in range(1, 23)] + [\"chrX\"]\n",
        "track = 0\n",
        "\n",
        "columns = [\"Cell Type\"]\n",
        "for name in gene_names:\n",
        "    columns.append(name)\n",
        "\n",
        "# Make dataset with gene names as the columns.\n",
        "dataset = pd.DataFrame(columns = columns)\n",
        "\n",
        "while track < len(noDisease_bw_data):\n",
        "    print(str(track/len(noDisease_bw_data)) + \"% Progress (\" + str(track) + \"/\" + str(len(noDisease_bw_data)) + \" Complete)\")\n",
        "    cell_type = noDisease_bw_data.iloc[track][\"Cell type\"]\n",
        "    \n",
        "    # Retrieve the file containing the methylation data for the cell_type\n",
        "    # Don't need coverage file for now - may integrate into more advanced algorithms\n",
        "    call_url = noDisease_bw_data.iloc[track][\"URL\"]\n",
        "    ! wget \"$call_url\" -N -q\n",
        "\n",
        "    call_file = call_url.split(\"/\")[-1]\n",
        "\n",
        "    data = [cell_type]\n",
        "    with pyBigWig.open(call_file) as call_object:\n",
        "        for name in gene_names:\n",
        "            try:\n",
        "                chrom, start, end = gene_locs[name]\n",
        "                # Get methylation data for particular gene\n",
        "                gene_cpgs = call_object.intervals(chrom, start, end)\n",
        "                # If some data exists, average over it and add it into the data for cell_type\n",
        "                if gene_cpgs is not None:\n",
        "                    gene_cpgs = [tup[2] for tup in gene_cpgs]\n",
        "                    data.append(sum(gene_cpgs)/len(gene_cpgs))\n",
        "                # If no data exists for the gene, put a -1 into the data for cell_type\n",
        "                else:\n",
        "                    data.append(-1)\n",
        "            except KeyError:\n",
        "                continue\n",
        "\n",
        "    dataset.loc[len(dataset.index)] = data\n",
        "\n",
        "    os.remove(call_file)\n",
        "\n",
        "    track += 2"
      ],
      "metadata": {
        "id": "bxwPgoR739EJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dataset Modifications"
      ],
      "metadata": {
        "id": "3XHubF33_r1L"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Models need at least two examples for training - one for the training set, and another for the validation/testing. If a particular cell type only has one example in the dataset, we must remove it."
      ],
      "metadata": {
        "id": "SD5GaxOR_89E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for cell_type in dataset[\"Cell Type\"].unique():\n",
        "    if len(dataset[dataset[\"Cell Type\"] == cell_type]) == 1:\n",
        "        dataset.drop(dataset[dataset['Cell Type'] == cell_type].index, inplace = True)"
      ],
      "metadata": {
        "id": "ZHqtp5WH_uKx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "For the purposes of this experiment, there is too little data for the number of unique cell types in our dataset, so we are grouping similar cell types under the same label, and deleting some we deemed too niche."
      ],
      "metadata": {
        "id": "S83gZGhPAXdy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Additionally, we only kept the 500 columns (ie genes) with the most variance in average methylation over all cell examples"
      ],
      "metadata": {
        "id": "sLyUtXuZB9QY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = dataset.drop(columns=dataset.columns[(dataset == -1).any()])\n",
        "breh = np.array(dataset.drop(\"Cell Type\", axis = 1))\n",
        "# Get the variances with respect to the genes\n",
        "var = np.var(breh, axis = 0)\n",
        "\n",
        "# Only keep the genes with the 500 highest variances of methylation.\n",
        "top_500 = list(np.argsort(var)[-500:])\n",
        "top_500.append(0)\n",
        "top_500_values = [var[i] for i in top_500]\n",
        "\n",
        "filtered_dataset = dataset.iloc[:, top_500]\n",
        "\n",
        "# These cells will be deleted.\n",
        "delete = [\"hematopoietic multipotent progenitor cell\", \"CD14-positive, CD16-negative classical monocyte\",\n",
        "          \"erythroblast\", \"CD34-negative, CD41-positive, CD42-positive megakaryocyte cell\", \"endothelial cell of umbilical vein (proliferating)\",\n",
        "          \"endothelial cell of umbilical vein (resting)\", \"CD3-negative, CD4-positive, CD8-positive, double positive thymocyte\",\n",
        "          \"CD3-positive, CD4-positive, CD8-positive, double positive thymocyte\", \"osteoclast\", \"regulatory T cell\", \n",
        "          \"mature eosinophil\", \"adult endothelial progenitor cell\", \"mesenchymal stem cell of the bone marrow\",\n",
        "          \"cytotoxic CD56-dim natural killer cell\"]\n",
        "\n",
        "copy_dataset = filtered_dataset.copy(deep = True)\n",
        "\n",
        "for index, row in copy_dataset.iterrows():\n",
        "    if row[\"Cell Type\"] in delete:\n",
        "        filtered_dataset.drop(index, inplace = True)\n",
        "        \n",
        "# These cells will be labeled as a neutrophil.\n",
        "neutrophil = [\"band form neutrophil\", \"neutrophilic metamyelocyte\", \"neutrophilic myelocyte\",\n",
        "              \"segmented neutrophil of bone marrow\", \"mature neutrophil\"]\n",
        "\n",
        "# These cells will be labeled as a b_cell.\n",
        "b_cell = [\"CD38-negative naive B cell\", \"germinal center B cell\", \"class switched memory B cell\", \"memory B cell\",\n",
        "          \"naive B cell\"]\n",
        "\n",
        "# These cells will be labeled as a CD8 cell.\n",
        "cd8 = [\"CD8-positive, alpha-beta T cell\", \"CD8-positive, alpha-beta thymocyte\", \"effector memory CD8-positive, alpha-beta T cell\",\n",
        "       \"central memory CD8-positive, alpha-beta T cell\", \"effector memory CD8-positive, alpha-beta T cell, terminally differentiated\"]\n",
        "\n",
        "# These cells will be labeled as a CD4 cell.\n",
        "cd4 = [\"CD4-positive, alpha-beta thymocyte\", \"CD4-positive, alpha-beta T cell\", \"effector memory CD4-positive, alpha-beta T cell\",\n",
        "       \"central memory CD4-positive, alpha-beta T cell\"]\n",
        "\n",
        "# These cells will be labeled as a dendritic cell.\n",
        "dendritic = [\"immature conventional dendritic cell\", \"mature conventional dendritic cell\", \"conventional dendritic cell\"]\n",
        "\n",
        "# These cells will be labeled as a macrophage.\n",
        "macrophage = [\"inflammatory macrophage\", \"alternatively activated macrophage\", \"macrophage\"]\n",
        "\n",
        "copy_dataset = filtered_dataset.copy(deep = True)\n",
        "\n",
        "for index, row in copy_dataset.iterrows():\n",
        "    if row[\"Cell Type\"] in neutrophil:\n",
        "        filtered_dataset.at[index, \"Cell Type\"] = \"neutrophil\"\n",
        "    if row[\"Cell Type\"] in b_cell:\n",
        "        filtered_dataset.at[index, \"Cell Type\"] = \"B cell\"\n",
        "    if row[\"Cell Type\"] in cd8:\n",
        "        filtered_dataset.at[index, \"Cell Type\"] = \"CD8 Cell\"\n",
        "    if row[\"Cell Type\"] in cd4:\n",
        "        filtered_dataset.at[index, \"Cell Type\"] = \"CD4 Cell\"\n",
        "    if row[\"Cell Type\"] in dendritic:\n",
        "        filtered_dataset.at[index, \"Cell Type\"] = \"Dendritic Cell\"\n",
        "    if row[\"Cell Type\"] in macrophage:\n",
        "        filtered_dataset.at[index, \"Cell Type\"] = \"Macrophage\""
      ],
      "metadata": {
        "id": "tBBSUFQRAYQz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset.to_csv(\"full_dataset.csv\", index = False)"
      ],
      "metadata": {
        "id": "c9_ROLfwDPLs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "filtered_dataset.to_csv(\"filtered_dataset.csv\", index = False)"
      ],
      "metadata": {
        "id": "8IBj0MfdDSza"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}